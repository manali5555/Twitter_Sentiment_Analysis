{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal : Predict the Sentiments of Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<img src=\"https://www.al.al.leg.br/imagens/Twitterlogo.png/image\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Workflow\n",
    "\n",
    "- Import Files & Modules\n",
    "- Process Data\n",
    "- Exploratory Data Analysis\n",
    "- Modeling (Senetence Transformers)\n",
    "- Explainabilty (Using Lime)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Import Files & Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.losses import CosineSimilarityLoss\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from lime.lime_text import LimeTextExplainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. Process Data\n",
    "Concatenate Data for EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "train = pd.read_csv(\"data/twitter_training.csv\", header=None)\n",
    "train.rename(columns={0:'tweet_id', 1:'entity', 2:'sentiment', 3:'tweet'},inplace=True)\n",
    "train = train.dropna().reset_index(drop=True)\n",
    "train_id = train['tweet_id']\n",
    "train['sentiment_label'] = train['sentiment'].astype('category').cat.codes\n",
    "\n",
    "# Val\n",
    "val = pd.read_csv(\"data/twitter_validation.csv\", header=None)\n",
    "val.rename(columns={0:'tweet_id', 1:'entity', 2:'sentiment', 3:'tweet'},inplace=True)\n",
    "val = val.dropna().reset_index(drop=True)\n",
    "val_id = val['tweet_id']\n",
    "val['sentiment_label'] = val['sentiment'].astype('category').cat.codes\n",
    "\n",
    "df = pd.concat([train, val],axis=0).reset_index(drop=True)\n",
    "\n",
    "### EDA on unique tweets\n",
    "df = df.groupby(\"tweet_id\").head(1).reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C. EDA\n",
    "\n",
    "## 1. Sentiment Distribution among all tweets\n",
    "* Most common Sentiment among all tweets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "ax = sns.countplot(x='sentiment',data=df, palette='rainbow')\n",
    "plt.title(\"Sentiment Distribution \")\n",
    "\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Entity Distribution among all tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.catplot(data=df, x=\"entity\", kind=\"count\", aspect=2.5)\n",
    "a = plt.xticks(\n",
    "    rotation=45, \n",
    "    horizontalalignment='right',\n",
    "    fontsize='large'  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Top 10 Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = pd.DataFrame({'# of Tweets':df.entity.value_counts()}).head(10)\n",
    "topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Games** and **Social Media** are topics most discussed in this dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Most common Tweet Sentiment (Topic Wise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_sentiment = []\n",
    "for i in topics.index:\n",
    "    most_common_sentiment.append(df[df.entity==i]['sentiment'].value_counts().idxmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = pd.DataFrame({'# of Tweets':df.entity.value_counts().head(10), 'Most Common Sentiment': most_common_sentiment}).head(10)\n",
    "topics = topics.reset_index().rename(columns={'index':'entity'}) \n",
    "topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D. Modeling - Using a Sentence Transformer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('paraphrase-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Train embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embeddings = model.encode(train['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embeddings_dataframe = pd.DataFrame(train_embeddings)\n",
    "train_embeddings_dataframe['tweet_id'] = train_id\n",
    "train_embeddings_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embeddings_dataframe.to_csv(\"train_embeddings.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Validation embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_embeddings = model.encode(val['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_embeddings_dataframe = pd.DataFrame(val_embeddings)\n",
    "val_embeddings_dataframe['tweet_id'] = val_id\n",
    "val_embeddings_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_embeddings_dataframe.to_csv(\"val_embeddings.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Classification Head\n",
    "* Run from Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embeddings_dataframe = pd.read_csv(\"train_embeddings.csv\")\n",
    "val_embeddings_dataframe = pd.read_csv(\"val_embeddings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_embeddings_dataframe.drop(['tweet_id'],axis=1)\n",
    "y_train = train['sentiment_label']\n",
    "\n",
    "X_val = val_embeddings_dataframe.drop(['tweet_id'],axis=1)\n",
    "y_val = val['sentiment_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = XGBClassifier(tree_method='gpu_hist')\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_val, classifier.predict(X_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E. Explainabilty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-08T22:35:29.745734Z",
     "iopub.status.busy": "2023-03-08T22:35:29.744419Z",
     "iopub.status.idle": "2023-03-08T22:35:29.760751Z",
     "shell.execute_reply": "2023-03-08T22:35:29.758753Z",
     "shell.execute_reply.started": "2023-03-08T22:35:29.745679Z"
    }
   },
   "source": [
    "## 1. Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSentenceTransformer():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = SentenceTransformer('paraphrase-mpnet-base-v2')\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return self.model.encode(X)\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.transform(X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = XGBClassifier(tree_method='gpu_hist')\n",
    "pipe = make_pipeline(CustomSentenceTransformer(), classifier)\n",
    "display(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(train['tweet'], train['sentiment_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['Irrelevant', 'Negative', 'Neutral', 'Positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Explainer = LimeTextExplainer(class_names=class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Checking Different Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Experiment = Explainer.explain_instance(train[train.sentiment=='Negative']['tweet'].values[1], pipe.predict_proba, num_features=10, top_labels=1)\n",
    "Experiment.show_in_notebook(text=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Experiment = Explainer.explain_instance(train[train.sentiment=='Positive']['tweet'].values[1], pipe.predict_proba, num_features=10, top_labels=1)\n",
    "Experiment.show_in_notebook(text=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Experiment = Explainer.explain_instance(train[train.sentiment=='Neutral']['tweet'].values[1], pipe.predict_proba, num_features=10, top_labels=1)\n",
    "Experiment.show_in_notebook(text=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "nlp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
